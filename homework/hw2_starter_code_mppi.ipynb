{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from aa598.hw2_helper import simulate_dynamics\n",
    "from cbfax.dynamics import DynamicallyExtendedSimpleCar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 1.\n",
    "v_max = 2.0\n",
    "acceleration_max = 1.0\n",
    "acceleration_min = -1.0\n",
    "steering_max = 0.3\n",
    "steering_min = -0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def evaluate_trajectory_cost(robot_states, robot_controls, human_states_samples, coeff=[0.1, 0.3, 0.5, 0.4, 3., 3.]):\n",
    "    # lower is better\n",
    "    steering = robot_controls[:,1]\n",
    "    acceleration = robot_controls[:,0]\n",
    "    # steering effort\n",
    "    turning_effort = (steering**2).mean() \n",
    "    # acceleration effort\n",
    "    acceleration_effort = (acceleration**2).mean() \n",
    "    # speed limit\n",
    "    speed = jax.nn.relu(robot_states[:,-1].max() - v_max) + jax.nn.relu(-robot_states[:,-1].min()) \n",
    "    # progress to goal\n",
    "    progress = robot_states[-1,2]**2 + (robot_states[:,1]**2).mean()\n",
    "    # collision \n",
    "    collision = jax.nn.relu(-(jnp.linalg.norm((robot_states - human_states_samples)[:,:,:2], axis=-1).min(-1) - radius).mean())\n",
    "    # control limits\n",
    "    control_limits = jax.nn.relu(steering.max() - steering_max) + jax.nn.relu(steering_min - steering.min()) + jax.nn.relu(acceleration.max() - acceleration_max) + jax.nn.relu(acceleration_min - acceleration.min()) \n",
    "\n",
    "    return jnp.dot(jnp.array(coeff), jnp.array([turning_effort, acceleration_effort, speed, progress, collision, control_limits]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_horizon = 25 # planning horizon to compute cost over\n",
    "n_human_samples = 64 # number of human future trajectories to sample\n",
    "n_robot_samples = 32 # number of robot trajectories to sample for MPPI\n",
    "dt = 0.1 # timestep size\n",
    "num_iterations = 20 # number of MPPI iteraciotns\n",
    "num_time_steps = 50 # number of timesteps to simulate\n",
    "human_control_prediction_noise_limit = 0.25\n",
    "human_control_prediction_variance = 0.25\n",
    "robot_control_noise_limit = 0.25\n",
    "robot_control_noise_variance = 0.25\n",
    "\n",
    "\n",
    "robot = DynamicallyExtendedSimpleCar() # robot dynamics\n",
    "human = DynamicallyExtendedSimpleCar() # human dynamics\n",
    "\n",
    "# initial states\n",
    "robot_state = jnp.array([-3.0, -0., 0., 1.])\n",
    "human_state = jnp.array([-1., -2., jnp.pi/2., 1.])\n",
    "# nominal controls\n",
    "robot_nominal_controls = jnp.zeros([planning_horizon, robot.control_dim])\n",
    "# assume human wants to follow a constant velocity mode (i.e., zero control input)\n",
    "human_nominal_controls = jnp.zeros([planning_horizon, human.control_dim])\n",
    "\n",
    "# making lists of things for plotting later\n",
    "robot_trajectory = [robot_state]\n",
    "human_trajectory = [human_state]\n",
    "robot_controls_list = []\n",
    "human_controls_list = []\n",
    "human_samples = []\n",
    "robot_nominal_controls_list = [robot_nominal_controls]\n",
    "\n",
    "coeffs = [0.2, 0.1, 5., 2., 10., 5.]   # <----- try different values!\n",
    "\n",
    "for ti in range(num_time_steps):\n",
    "    # very simple human prediction model -- just gaussian noise about a constant velocity model.\n",
    "    dus = jnp.clip(jnp.array(np.random.randn(n_human_samples, planning_horizon, human.control_dim) * human_control_prediction_variance), -human_control_prediction_noise_limit, human_control_prediction_noise_limit)\n",
    "    human_controls_samples = jnp.clip(human_nominal_controls + dus, min=jnp.array([acceleration_min, steering_min]), max=jnp.array([acceleration_max, steering_max]))\n",
    "    human_states_samples = jax.vmap(simulate_dynamics, [None, None, 0, None])(human, human_state, human_controls_samples, dt)\n",
    "    human_samples.append(human_states_samples)\n",
    "    \n",
    "    for t in range(num_iterations):\n",
    "        temperature = 1 - (t / num_iterations)\n",
    "        # sampling robot control trajectories\n",
    "        dus = jnp.clip(jnp.array(np.random.randn(n_robot_samples, planning_horizon, robot.control_dim) * robot_control_noise_variance), -robot_control_noise_limit, robot_control_noise_limit)\n",
    "        robot_controls_samples = jnp.clip(robot_nominal_controls + dus, min=jnp.array([acceleration_min, steering_min]), max=jnp.array([acceleration_max, steering_max]))\n",
    "        # simulate robot trajectory for each control trajectory sample\n",
    "        robot_states_samples = jax.vmap(simulate_dynamics, [None, None, 0, None])(robot, robot_state, robot_controls_samples, dt)\n",
    "        # \n",
    "        # evaluate cost of each robot trajectory sample\n",
    "        trajectory_costs = jax.vmap(evaluate_trajectory_cost, [0, 0, None, None])(robot_states_samples, robot_controls_samples, human_states_samples, coeffs)\n",
    "        # weight for each trajectory sample\n",
    "        weights = jax.nn.softmax(-trajectory_costs / temperature).reshape([-1, 1, 1])\n",
    "        # compute new nominal control using weighted sum\n",
    "        \n",
    "        robot_nominal_controls = jnp.clip(robot_nominal_controls + (dus * weights).sum(0), min=jnp.array([acceleration_min, steering_min]), max=jnp.array([acceleration_max, steering_max]))\n",
    "        \n",
    "    # use final nominal control to step forward in time by one step\n",
    "    robot_nominal_controls_list.append(robot_nominal_controls)\n",
    "    robot_state = simulate_dynamics(robot, robot_state, robot_nominal_controls[:1], dt)[-1]\n",
    "    human_state = simulate_dynamics(human, human_state, human_controls_samples[0][:1], dt)[-1]\n",
    "    # collect the new state and controls for plotting purposes\n",
    "    robot_trajectory.append(robot_state)\n",
    "    human_trajectory.append(human_state)\n",
    "    robot_controls_list.append(robot_nominal_controls[:1])\n",
    "    human_controls_list.append(human_controls_samples[0][:1])\n",
    "\n",
    "# turn things into jnp.array\n",
    "robot_trajectory = jnp.stack(robot_trajectory)\n",
    "human_trajectory = jnp.stack(human_trajectory)\n",
    "human_samples = jnp.stack(human_samples)\n",
    "robot_controls_list = jnp.concatenate(robot_controls_list, 0)\n",
    "human_controls_list = jnp.concatenate(human_controls_list, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6a7f7a0d444a0ab4977182e271fbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=24, description='i', max=49), Output()), _dom_classes=('widget-interact'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,num_time_steps-1))\n",
    "def plot(i):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(18,8))\n",
    "    ax = axs[0]\n",
    "    robot_position = robot_trajectory[i, :2]\n",
    "    human_position = human_trajectory[i, :2]\n",
    "    circle1 = plt.Circle(robot_position, radius / 2, color='C0', alpha=0.4)\n",
    "    circle2 = plt.Circle(human_position, radius / 2, color='C1', alpha=0.4)\n",
    "    ax.add_patch(circle1)\n",
    "    ax.add_patch(circle2)\n",
    "    ax.plot(human_samples[i,:,:,0].T, human_samples[i,:,:,1].T, \"o-\", alpha=0.1, markersize=2, color='C1')\n",
    "    ax.plot(robot_trajectory[:,0], robot_trajectory[:,1], \"o-\", markersize=3, color='C0')\n",
    "    ax.plot(human_trajectory[:,0], human_trajectory[:,1], \"o-\", markersize=3, color='C1')\n",
    "    ax.scatter(robot_trajectory[i:i+1,0], robot_trajectory[i:i+1,1], s=30,  color='C0', label=\"Robot\")\n",
    "    ax.scatter(human_trajectory[i:i+1,0], human_trajectory[i:i+1,1], s=30,  color='C1', label=\"Human\")\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.axis(\"equal\")\n",
    "    ax.set_xlim([-4,4])\n",
    "    ax.set_ylim([-3, 6])\n",
    "\n",
    "    ax.set_title(\"heading=%.2f velocity=%.2f\"%(robot_trajectory[i,2], robot_trajectory[i,3]))\n",
    "    \n",
    "    ax = axs[1]\n",
    "    plt.plot(robot_controls_list)\n",
    "    plt.scatter([i], robot_controls_list[i:i+1, 0], label=\"Acceleration\")\n",
    "    plt.scatter([i], robot_controls_list[i:i+1, 1], label=\"Steering\")\n",
    "    ax.plot(robot_trajectory[:,-1], \"o-\", markersize=3, color='C0', label=\"Velocity\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
